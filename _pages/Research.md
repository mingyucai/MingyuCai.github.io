---
layout: archive
title: ""
permalink: /Research/
author_profile: true
---

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top">
              <img src='images/hamadapt/gif/quadrotor/32/video_exp1_adaptive32.gif' width="220">
               <br>
                 <img src='images/hamadapt/gif/quadrotor/32/exp1_adaptive_3d.gif' width="220">
            </td>
            <td style="https://arxiv.org/abs/2109.02791">
              <a href="https://thaipduong.github.io/hamadapt/">
                  <papertitle><strong>Safe-Critical Modular Deep Reinforcement Learning with Temporal Logic through Gaussian Processes and Control Barrier Functions</strong></papertitle>
              </a>
              <br>
              <strong>Mingyu Cai</strong>,
              <a Cristian-Ioan Vasile</a>
              <br>
              <br>
              <a href="https://www.youtube.com/watch?v=fkCyAgx_FWM/">Video</a> /
              <a href="https://arxiv.org/abs/2109.02791">PDF</a>
              <p></p>
              <p>Reinforcement learning (RL) is a promising approach. However, success is limited towards real-world applications, because ensuring safe exploration and facilitating adequate exploitation is a challenge for controlling robotic systems with unknown models and measurement uncertainties. The learning problem becomes even more difficult for complex tasks over continuous state-space and action-space. In this project, we propose a learning-based control framework to satisfy high-level complex task while ensure safe during training. The algorithm is tested in the case of Marx exploration. </p>
              <p> <center> <img src='/papers_files/Safety_Critical/Demo.png' width="620"> </center></p>   
  </td>
</tr>

</tbody></table>

      
     
              
              


     

