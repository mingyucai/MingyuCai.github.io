---
title: "Safe-Critical Modular Deep Reinforcement Learning with Temporal Logic"
collection: talks
type: "Lehigh AIR Lab Talk"
permalink: /talks/2021-10-21-talkl-4
venue: ""
date: 2021-10-19
location: "Bethlehem, PA"
---

[Talk Presentation](https://www.youtube.com/watch?v=84kze5vhbOg)

Reinforcement learning (RL) is a promising approach.
However, success is limited to real-world applications, because ensuring safe exploration and facilitating adequate exploitation is a challenge for controlling robotic systems with unknown models and measurement uncertainties.
The learning problem becomes even more difficult for complex tasks over continuous state-space and action-space.
In this paper, we propose a learning-based robotic control framework consisting of several aspects:
(1) we leverage Linear Temporal Logic (LTL) to express complex tasks over infinite horizons that are translated to a novel automaton structure;
(2) we detail an innovative reward scheme for LTL satisfaction with a probabilistic guarantee. Then, by applying a reward shaping technique, we develop a modular policy-gradient architecture exploiting the benefits of the automaton structure to decompose overall tasks and enhance the performance of learned controllers;
(3) by incorporating Gaussian Processes (GPs) to estimate the uncertain dynamic systems, we synthesize a model-based safe exploration during the learning process using Exponential Control Barrier Functions (ECBFs) that generalize systems with high-order relative degrees.
(4) to further improve the efficiency of exploration, we utilize the properties of LTL automata and ECBFs to propose a safe guiding process.
Finally, we demonstrate the effectiveness of the framework via several robotic environments.
We show an ECBF-based modular deep RL algorithm that achieves near-perfect success rates and safety guarding with high probability confidence during training. 

